# ğŸš€ GA02: Multi-Document Hybrid RAG Search Engine
*(Document Retrieval + Real-Time Web Search)*
---

## ğŸ“Œ Project Overview

This project implements a **Hybrid Retrieval-Augmented Generation (RAG) Search Engine** that combines:

- Semantic search over multiple local documents
- Real-time web search using Tavily
- Citation-aware answer generation
- An interactive Streamlit-based chatbot UI

The system mirrors real-world **enterprise AI copilots** that intelligently blend **private knowledge bases** with **live internet data**, while maintaining **source transparency** and **answer grounding**.

---

## ğŸ¯ Objectives

The primary goals of this project are to:

- Build a searchable knowledge base from multiple unstructured documents
- Perform semantic retrieval using FAISS
- Integrate real-time web search via Tavily
- Dynamically route queries between:
  - ğŸ“„ Document-based search
  - ğŸŒ Web-based search
  - ğŸ”€ Hybrid search
- Generate grounded answers with clear citations
- Provide a clean, user-friendly Streamlit UI

---

## ğŸ§  System Architecture

User Query
â”‚
â–¼
Query Classification (Document / Web / Hybrid)
â”‚
â”œâ”€â”€ FAISS Vector Search (Local Docs)
â”œâ”€â”€ Tavily Web Search (Real-Time)
â–¼
Context Assembly
â–¼
LLM (Groq via LangChain)
â–¼
Answer + Citations
â–¼
Streamlit UI


---

## ğŸ›  Tech Stack (Strictly Followed)

| Component | Technology |
|---------|------------|
| Language | Python |
| LLM Orchestration | LangChain |
| LLM Provider | Groq |
| Vector Database | FAISS |
| Embeddings | Sentence-Transformers |
| Web Search | Tavily |
| UI | Streamlit |

---

## ğŸ“‚ Project Structure

GA02_Hybrid_RAG/
â”‚
â”œâ”€â”€ app.py # Streamlit UI
â”œâ”€â”€ config.py # Configuration & constants
â”œâ”€â”€ loaders.py # PDF / TXT / Wikipedia loaders
â”œâ”€â”€ models.py # Unified document schemas
â”œâ”€â”€ text_utils.py # Text cleaning & chunking
â”œâ”€â”€ vectorstore.py # FAISS indexing & loading
â”œâ”€â”€ web_search.py # Tavily integration
â”œâ”€â”€ rag_pipeline.py # Hybrid RAG logic
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ documents/ # Uploaded files
â”‚ â””â”€â”€ faiss_index/ # Saved FAISS index
â”‚
â””â”€â”€ venv/


---

## ğŸ“¥ Data Sources

### Local Knowledge Base
- PDF documents
- Text files
- Wikipedia pages (LangChain loader)

### Real-Time Knowledge
- Tavily web search results:
  - News
  - Current events
  - Recent research
  - Live statistics

---

## ğŸ§© Key Features

### âœ… Multi-Document Ingestion
- Supports PDFs, TXT files, and Wikipedia pages
- Unified metadata schema for traceability

### âœ… Semantic Search
- Recursive chunking with overlap
- FAISS-based vector similarity search

### âœ… Hybrid RAG Pipeline
- Intelligent query routing
- Document-only, web-only, or hybrid context assembly

### âœ… Citation-Aware Answers
- Distinguishes between:
  - `[Doc]` document sources
  - `[Web]` Tavily search sources

### âœ… Streamlit UI
- Upload & index documents
- Toggle web search ON/OFF
- Answer & source tabs
- Visual route indicators:
  - ğŸ“„ Document-based
  - ğŸŒ Web-based
  - ğŸ”€ Hybrid

---

## ğŸ”’ Document Grounding Behavior

When **Tavily Web Search is OFF**, the system:

- Answers **only if the information exists in uploaded documents**
- Otherwise responds:

> **â€œThe answer is not available in the provided documents.â€**

This ensures **strict document grounding** and prevents hallucinations.

---

## ğŸ§ª Evaluation Scenarios

| Scenario | Expected Behavior |
|--------|-------------------|
| Static knowledge query | Retrieved from documents |
| Real-time factual query | Retrieved via Tavily |
| Hybrid reasoning query | Combined document + web context |

---

## ğŸ“Š Quality Assessment

### Strengths
- Modular and scalable architecture
- Clear source attribution
- Real-time + private knowledge fusion
- Production-style UI

### Limitations
- Rule-based query classification
- No re-ranking of retrieved chunks
- No automatic top-N document summarization

### Future Enhancements
- ML-based query classifier
- Chunk re-ranking (Cross-Encoder)
- Document-level summarization
- Conversation memory
- Authentication for enterprise use

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Create Virtual Environment
```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

2ï¸âƒ£ Install Dependencies
-pip install -r requirements.txt

3ï¸âƒ£ Configure .env
Gemini_API_KEY=your_gemini_key
TAVILY_API_KEY=your_tavily_key

4ï¸âƒ£ Run the App
streamlit run app.py

ğŸ Final Outcome

By completing this project, the following learning outcomes are demonstrated:

âœ… Multi-document RAG system design

âœ… Hybrid retrieval (vector + web)

âœ… Tavily real-time search integration

âœ… Citation-aware answer generation

âœ… Practical LangChain + Streamlit skills





---
